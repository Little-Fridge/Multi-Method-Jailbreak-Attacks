# 基于专业知识
python /share/project/test/backup/arc/ppx/wetexp/prompt_knowledge.py \
  -i /share/project/test/backup/arc/ppx/wetexp/data/prompts.jsonl \
  -o knowledge_results.jsonl \
  -m /share/project/test/backup/arc/ppx/llava-1.5-7b-hf

# PAIR算法
python /share/project/test/backup/arc/ppx/wetexp/PAIR_LLaVA.py \
  --input /share/project/test/backup/arc/ppx/wetexp/data/prompts.jsonl \
  --output pair_llava16_results.jsonl \
  --atk_model /share/project/test/backup/arc/ppx/llava-1.5-7b-hf \
  --tgt_model /share/project/test/backup/arc/ppx/llava-1.5-13b-hf \
  --max_iter 12

python /share/project/test/backup/arc/ppx/wetexp/PAIR_Qwen.py \
  --input /share/project/test/backup/arc/ppx/wetexp/data/prompts.jsonl \
  --output pair_llava16_results.jsonl \
  --atk_model /share/project/test/backup/arc/ppx/llava-1.5-7b-hf \
  --tgt_model /share/project/test/backup/arc/ppx/Qwen1.5-7B-Chat \
  --max_iter 12

python /share/project/test/backup/arc/ppx/wetexp/PAIR_GLM.py \
  --input /share/project/test/backup/arc/ppx/wetexp/data/prompts.jsonl \
  --output pair_llava16_results.jsonl \
  --atk_model /share/project/test/backup/arc/ppx/llava-1.5-7b-hf \
  --tgt_model /share/project/test/backup/arc/ppx/chatglm3-6b \
  --max_iter 12

python /share/project/test/backup/arc/ppx/wetexp/PAIR_BaiChuan.py \
  --input /share/project/test/backup/arc/ppx/wetexp/data/prompts.jsonl \
  --output pair_results.jsonl \
  --atk_model /share/project/test/backup/arc/ppx/llava-1.5-7b-hf \
  --tgt_model /share/project/test/backup/arc/ppx/Baichuan2-7B-Chat \
  --max_iter 12

python /share/project/test/backup/arc/ppx/wetexp/PAIR_DeepSeek.py \
  --input /share/project/test/backup/arc/ppx/wetexp/data/prompts.jsonl \
  --output pair_results.jsonl \
  --atk_model /share/project/test/backup/arc/ppx/llava-1.5-7b-hf \
  --tgt_model /share/project/test/backup/arc/ppx/deepseek-llm-7b-chat \
  --max_iter 12

python /share/project/test/backup/arc/ppx/wetexp/PAIR_GPT.py \
  --input /share/project/test/backup/arc/ppx/wetexp/data/prompts.jsonl \
  --output pair_results.jsonl \
  --atk_model /share/project/test/backup/arc/ppx/llava-1.5-13b-hf \
  --tgt_model gpt-4o \
  --max_iter 12

python /share/project/test/backup/arc/ppx/wetexp/GCG_ChatGlm.py \
--prompts_file /share/project/test/backup/arc/ppx/wetexp/data/prompts.jsonl \
--save_json /share/project/test/backup/arc/ppx/wetexp/GCG.json
--model_path /share/project/test/backup/arc/ppx/chatglm3-6b \

python /share/project/test/backup/arc/ppx/wetexp/GCG_ChatGlm.py \
--prompts_file /share/project/test/backup/arc/ppx/wetexp/data/test.jsonl \
--save_json /share/project/test/backup/arc/ppx/wetexp/GCG.json
--model_path /share/project/test/backup/arc/ppx/chatglm3-6b \


torchrun \
--nproc_per_node=8 \
/share/project/test/backup/arc/ppx/wetexp/GCG_ChatGlm.py \
--model_path /share/project/test/backup/arc/ppx/chatglm3-6b \
--prompts_file /share/project/test/backup/arc/ppx/wetexp/data/prompts.jsonl \ 
--save_json /share/project/test/backup/arc/ppx/wetexp/GCG.json \